# AI 员工记忆系统（Memory System）

> 目标：让 AI 员工像真实员工一样，**记住人、事、项目与经验**，但不会记错、记乱、记太多，也不会显著增加上下文与推理成本。

---

## 一、产品定位（PRD 概览）

### 1. 产品一句话定义

**AI 员工记忆系统 = 一个“可写、可忘、可纠错、可检索、低上下文成本”的长期工作记忆系统。**

它不是聊天记录仓库，而是：
- 为未来决策服务的**工作记忆**
- 为人协作服务的**关系记忆**
- 为效率服务的**经验记忆**

---

### 2. 核心目标

| 目标 | 解释 |
|---|---|
| 像员工 | 记住项目、客户、上下文，而不是每次从零开始 |
| 不爆 token | 永远不把“全部记忆”塞进上下文 |
| 不串人 | 多用户、多角色绝对隔离 |
| 可纠错 | 记忆是“带置信度的假设”，可被修正 |
| 可进化 | 记忆会合并、升级、衰减 |

---

### 3. 非目标（明确不做）

- ❌ 不做逐字聊天存档（那是日志系统）
- ❌ 不做训练期参数更新（避免灾难性遗忘）
- ❌ 不追求“记住一切”

---

## 二、用户与使用场景

### 1. 典型用户

- 企业主 / 创始人
- 产品经理 / 技术负责人
- 销售 / 客服 / 运营 AI 员工

---

### 2. 典型场景

#### 场景 A：长期项目协作
- AI 记住：项目目标、技术栈、约束、阶段状态
- 新对话自动对齐上下文

#### 场景 B：客户/同事协作
- 记住：沟通偏好、历史决策、关键约定
- 避免重复解释

#### 场景 C：经验沉淀
- 记住：什么方案行得通 / 行不通
- 下次主动规避错误路径

---

## 三、记忆系统整体设计（核心思想）

### 1. 记忆分层模型（非常关键）

```
短期记忆（Working Memory）
  └ 当前上下文窗口

中期记忆（Session / Episodic Memory）
  └ 会话摘要 / 事件

长期记忆（Long-term Memory）
  └ 用户 / 项目 / 偏好 / 经验

公共语义记忆（World / Engram）
  └ 不属于本系统（模型侧）
```

---

### 2. 记忆的基本原则

- **记忆是“为未来降低决策成本”**
- 所有记忆必须：
  - 可结构化
  - 可合并
  - 可衰减
  - 可修正

---

## 四、记忆写入机制（Write Path）

### 1. 写入不是自动的，而是“筛选后写入”

#### 写入流程：

```
对话结束
 ↓
生成记忆候选（Memory Candidates）
 ↓
多维评分（4 分）
 ↓
超过阈值 → 写入
否则 → 丢弃
```

---

### 2. 四个写入评分维度

| 维度 | 含义 |
|---|---|
| 重复性 | 是否被多次提及 |
| 持久性 | 是否容易过期 |
| 个体相关性 | 是否和这个用户/项目强相关 |
| 决策价值 | 未来是否会影响决策 |

> 只有 ≥2~3 项为高，才允许写入长期记忆。

---

### 3. 记忆结构定义（示例）

```json
{
  "memory_id": "uuid",
  "owner_id": "user_123",
  "role_id": "ai_pm",
  "type": "long_term_fact",
  "content": "用户正在开发万亿参数模型的记忆系统",
  "confidence": 0.82,
  "support": 4,
  "contradict": 0,
  "created_at": "2026-01-13",
  "last_seen": "2026-01-13"
}
```

---

## 五、记忆修正机制（Correct Path）

### 1. 记忆不是事实，而是“假设 + 置信度”

- 新对话会不断提供：
  - 正向证据
  - 反向证据

---

### 2. 三阶段修正机制

1. **降权**：confidence ↓，减少使用概率
2. **冻结**：不再检索，仅保留历史
3. **替换**：新记忆取代旧记忆

---

## 六、记忆读取机制（Read Path）——解决 token 成本

### 1. 绝不全量注入上下文

#### 注入策略分三类：

| 层级 | 数量 | 是否常驻 |
|---|---|---|
| 核心偏好 | ≤5 条 | 是 |
| 相关记忆 | 3~8 条 | 按需 |
| 冷存档 | 无限 | 否 |

---

### 2. 两阶段检索（强烈推荐）

#### 阶段 1：目录级
- 只返回主题 / 项目名（几十 tokens）

#### 阶段 2：命中后再取细节

---

### 3. 注入预算控制

- 单轮记忆预算：300~800 tokens
- 超出必须：合并 / 压缩 / 丢弃

---

## 七、多用户、多角色隔离设计（防串记忆）

### 1. 记忆 Key 设计

```
(user_id, role_id, memory_type)
```

- 不允许跨 user_id
- role_id 默认隔离（除非显式允许）

---

### 2. 会话级隔离

- Session 结束 → 自动摘要
- 原始上下文丢弃

---

## 八、技术架构（Engineering Architecture）

### 1. 总体架构图（逻辑）

```
┌───────────┐
│   LLM     │
└────┬──────┘
     │
     ▼
┌──────────────┐
│ Memory Controller │  ← 决定是否用记忆
└────┬─────────┘
     │
     ▼
┌──────────────┐
│ Memory Retriever │ ← 向量 / 结构检索
└────┬─────────┘
     │
     ▼
┌──────────────┐
│ Context Builder │ ← 预算控制
└──────────────┘
```

---

### 2. 技术选型建议

| 模块 | 推荐 |
|---|---|
| 向量库 | FAISS / Milvus / Qdrant |
| 结构存储 | PostgreSQL / DynamoDB |
| 控制器 | 轻量 LLM / rule + LLM |
| 序列化 | JSON Schema |

---

## 九、最小可行版本（MVP）

### Phase 1（2~3 周）
- 长期记忆写入 + 检索
- Top-K 注入
- 多用户隔离

### Phase 2
- 置信度 / 衰减 / 合并
- 角色隔离

### Phase 3
- 自动纠错
- 目录级记忆
- 记忆工具调用

---

## 十、一句话产品总结（给团队）

> **AI 员工的核心竞争力不是“回答问题”，
而是：
“下次不再犯同样的错误，并且越来越懂你”。**

---

如果你愿意，我可以下一步直接帮你：
- 把这套方案拆成 **API 设计（接口级）**
- 或输出一版 **Memory Controller 的 Prompt & 规则模板**
- 或对接你现有的 AI 员工架构做“落地适配图”

